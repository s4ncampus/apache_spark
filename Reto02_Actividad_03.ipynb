{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                                  \n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                              \n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.log4j.{Level, Logger}\n",
       "\u001b[39m"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//Import para Jupyter-notebooks \n",
    "import $ivy.`org.apache.spark::spark-sql:2.4.0`\n",
    "import $ivy.`sh.almond::almond-spark:0.6.0`\n",
    "import org.apache.log4j.{Level, Logger}\n",
    "Logger.getLogger(\"org\").setLevel(Level.OFF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Funciones de agregación más utilizadas\n",
    "\n",
    "1. Definir la sesión de Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading spark-stubs\n",
      "Getting spark JARs\n",
      "Creating SparkSession\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a href=\"http://192.168.6.17:4040\">Spark UI</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql._\n",
       "\n",
       "\u001b[39m\n",
       "\u001b[36mspark\u001b[39m: \u001b[32mSparkSession\u001b[39m = org.apache.spark.sql.SparkSession@1fa7409a"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql._\n",
    "\n",
    "val spark = {\n",
    "  NotebookSparkSession.builder()\n",
    "    .master(\"local[*]\")\n",
    "    .getOrCreate()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Crear un dataframe desde un archivo plano ubicación: resources/Impuesto_de_Transporte_-_MinEnerg_a.csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "shown",
    "solution2_first": true
   },
   "outputs": [],
   "source": [
    "import spark.implicits._\n",
    "val impuestoDf = ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "solution2": "shown"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>\n",
       "var comm = Jupyter.notebook.kernel.comm_manager.new_comm('cancel-stage-583da89b-c3bc-4cad-b7ed-dba137e2eabb', {});\n",
       "\n",
       "function cancelStage(stageId) {\n",
       "  console.log('Cancelling stage ' + stageId);\n",
       "  comm.send({ 'stageId': stageId });\n",
       "}\n",
       "</script>\n",
       "          "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "  <span style=\"float: left;\">load at cmd2.sc:2</span>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"progress\">\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: blue; width: 100%; word-wrap: normal; white-space: nowrap; text-align: center; color: white\" aria-valuenow=\"100\" aria-valuemin=\"0\" aria-valuemax=\"100\">\n",
       "    1 / 1\n",
       "  </div>\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: red; width: 0%\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\"></div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36mspark.implicits._\n",
       "\u001b[39m\n",
       "\u001b[36mimpuestoDf\u001b[39m: \u001b[32mDataFrame\u001b[39m = [ano: string, trimestre: string ... 6 more fields]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spark.implicits._\n",
    "val impuestoDf = spark.read.format(\"csv\").option(\"header\",true).load(\"resources/Impuesto_de_Transporte_-_MinEnerg_a.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Cálcula cuantos elementos tiene el dataframe, pero que no sea una acción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.functions.count\n",
    "impuestoDf.select(count(\"ano\")).show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Ahora cálcula la suma del totalimpuestos pagados durante el año 2019 trimestre 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "shown",
    "solution2_first": true
   },
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.functions.sum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "shown"
   },
   "outputs": [],
   "source": [
    "// dataframes\n",
    "import org.apache.spark.sql.functions.sum\n",
    "impuestoDf.where(\"ano = 2019 and trimestre = 1\").select(sum(\"totalimpuesto\").as(\"total\")).show()\n",
    "// SQL\n",
    "impuestoDf.createOrReplaceTempView(\"impuestos\")\n",
    "spark.sql(\"select sum(totalimpuesto) as total from impuestos where ano = 2019 and trimestre = 1\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Calcula el total de impuestos pagos en el año 2019 trimestre 1, el total pagado, el promedio pagadao , el menor impuesto y el mayor impuesto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "shown",
    "solution2_first": true
   },
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.functions.{sum, count, avg, min, max}\n",
    "\n",
    "val totals = ???\n",
    "totals.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "shown"
   },
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.functions.{sum, count, avg, min, max}\n",
    "\n",
    "val totals = impuestoDf.where(\"ano = 2019 and trimestre = 1\").select(\n",
    "    count(\"totalimpuesto\").alias(\"numImpuestos\"),\n",
    "    sum(\"totalimpuesto\").as(\"totalPagado\"),\n",
    "    avg(\"totalimpuesto\").as(\"promedioPagado\"),\n",
    "    max(\"totalimpuesto\").as(\"MayorTotalPagado\"),\n",
    "    min(\"totalimpuesto\").as(\"MenorTotalPagado\")    \n",
    ")\n",
    "\n",
    "totals.show()\n",
    "// esta función sirve para describir una columna, obtiene el count, mean, desviación estandar, min y max.\n",
    "impuestoDf.select(\"totalimpuesto\").describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Agrupa la información por departament, primero con la función de los dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "shown",
    "solution2_first": true
   },
   "outputs": [],
   "source": [
    "impuestoDf._____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "shown"
   },
   "outputs": [],
   "source": [
    "impuestoDf.groupBy('departamento).count().orderBy('count).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.b. Ahora obten el mismo resultado ejecutando la sentencia SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "shown",
    "solution2_first": true
   },
   "outputs": [],
   "source": [
    "_______('impuestosTable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "solution2": "shown"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "  <span style=\"float: left;\">show at cmd3.sc:2</span>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"progress\">\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: blue; width: 100%; word-wrap: normal; white-space: nowrap; text-align: center; color: white\" aria-valuenow=\"100\" aria-valuemin=\"0\" aria-valuemax=\"100\">\n",
       "    1 / 1\n",
       "  </div>\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: red; width: 0%\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\"></div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "  <span style=\"float: left;\">show at cmd3.sc:2</span>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"progress\">\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: blue; width: 100%; word-wrap: normal; white-space: nowrap; text-align: center; color: white\" aria-valuenow=\"100\" aria-valuemin=\"0\" aria-valuemax=\"100\">\n",
       "    200 / 200\n",
       "  </div>\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: red; width: 0%\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\"></div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-----+\n",
      "|      departamento|count|\n",
      "+------------------+-----+\n",
      "|   DEPARTAMENTO NN|   12|\n",
      "|             CAUCA|   14|\n",
      "|            CALDAS|   18|\n",
      "|      CUNDINAMARCA|   48|\n",
      "|            ARAUCA|   54|\n",
      "|              META|   68|\n",
      "|          PUTUMAYO|  102|\n",
      "|             HUILA|  108|\n",
      "|         MAGDALENA|  112|\n",
      "|          CASANARE|  128|\n",
      "|           BOLIVAR|  140|\n",
      "|         ANTIOQUIA|  142|\n",
      "|             CESAR|  144|\n",
      "|           CORDOBA|  170|\n",
      "|            NARIÑO|  180|\n",
      "|         SANTANDER|  184|\n",
      "|NORTE DE SANTANDER|  192|\n",
      "|             SUCRE|  201|\n",
      "|            TOLIMA|  335|\n",
      "|            BOYACA|  391|\n",
      "+------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "impuestoDf.createOrReplaceTempView(\"impuestosTable\")\n",
    "spark.sql(\"SELECT departamento,count(1) as count FROM impuestosTable GROUP BY departamento ORDER BY count\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Calcula el totalimpuesto cancelado por cada departamento ordenado desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "//SQL \n",
    "spark.sql(\"\"\"\n",
    "SELECT departamento,sum(totalimpuesto) as total \n",
    "FROM impuestosTable GROUP BY departamento ORDER BY total desc\n",
    "\"\"\").show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala",
   "language": "scala",
   "name": "scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "nbconvert_exporter": "script",
   "version": "2.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
