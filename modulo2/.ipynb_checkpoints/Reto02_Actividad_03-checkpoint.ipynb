{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "//Import para Jupyter-notebooks \n",
    "import $ivy.`org.apache.spark::spark-sql:2.4.0`\n",
    "import $ivy.`sh.almond::almond-spark:0.6.0`\n",
    "import org.apache.log4j.{Level, Logger}\n",
    "Logger.getLogger(\"org\").setLevel(Level.OFF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Funciones de agregación más utilizadas\n",
    "\n",
    "1. Definir la sesión de Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.sql._\n",
    "\n",
    "val spark = {\n",
    "  NotebookSparkSession.builder()\n",
    "    .master(\"local[*]\")\n",
    "    .getOrCreate()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Crear un dataframe desde un archivo plano ubicación: resources/Impuesto_de_Transporte_-_MinEnerg_a.csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "outputs": [],
   "source": [
    "import spark.implicits._\n",
    "val impuestoDf = ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "import spark.implicits._\n",
    "val impuestoDf = spark.read.format(\"csv\").option(\"header\",true).load(\"resources/Impuesto_de_Transporte_-_MinEnerg_a.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Cálcula cuantos elementos tiene el dataframe, pero que no sea una acción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.functions.count\n",
    "impuestoDf.select(count(\"ano\")).show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Ahora cálcula la suma del totalimpuestos pagados durante el año 2019 trimestre 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.functions.sum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "// dataframes\n",
    "import org.apache.spark.sql.functions.sum\n",
    "impuestoDf.where(\"ano = 2019 and trimestre = 1\").select(sum(\"totalimpuesto\").as(\"total\")).show()\n",
    "// SQL\n",
    "impuestoDf.createOrReplaceTempView(\"impuestos\")\n",
    "spark.sql(\"select sum(totalimpuesto) as total from impuestos where ano = 2019 and trimestre = 1\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Calcula el total de impuestos pagos en el año 2019 trimestre 1, el total pagado, el promedio pagadao , el menor impuesto y el mayor impuesto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.functions.{sum, count, avg, min, max}\n",
    "\n",
    "val totals = ???\n",
    "totals.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.functions.{sum, count, avg, min, max}\n",
    "\n",
    "val totals = impuestoDf.where(\"ano = 2019 and trimestre = 1\").select(\n",
    "    count(\"totalimpuesto\").alias(\"numImpuestos\"),\n",
    "    sum(\"totalimpuesto\").as(\"totalPagado\"),\n",
    "    avg(\"totalimpuesto\").as(\"promedioPagado\"),\n",
    "    max(\"totalimpuesto\").as(\"MayorTotalPagado\"),\n",
    "    min(\"totalimpuesto\").as(\"MenorTotalPagado\")    \n",
    ")\n",
    "\n",
    "totals.show()\n",
    "// esta función sirve para describir una columna, obtiene el count, mean, desviación estandar, min y max.\n",
    "impuestoDf.select(\"totalimpuesto\").describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Agrupa la información por departament, primero con la función de los dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "outputs": [],
   "source": [
    "impuestoDf._____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "impuestoDf.groupBy('departamento).count().orderBy('count).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.b. Ahora obten el mismo resultado ejecutando la sentencia SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "outputs": [],
   "source": [
    "_______('impuestosTable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "impuestoDf.createOrReplaceTempView('impuestosTable)\n",
    "spark.sql(\"SELECT departamento,count(1) as count FROM impuestosTable GROUP BY departamento ORDER BY count\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Calcula el totalimpuesto cancelado por cada departamento ordenado desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "//SQL \n",
    "spark.sql(\"\"\"\n",
    "SELECT departamento,sum(totalimpuesto) as total \n",
    "FROM impuestosTable GROUP BY departamento ORDER BY total desc\n",
    "\"\"\").show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala",
   "language": "scala",
   "name": "scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "nbconvert_exporter": "script",
   "version": "2.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
